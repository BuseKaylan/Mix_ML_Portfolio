{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "226354ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f44f9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth','PetalLength', 'PetalWidth','Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85c4090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"iris_training.csv\", names = CSV_COLUMN_NAMES, header=0)\n",
    "test=pd.read_csv(\"iris_test.csv\", names=CSV_COLUMN_NAMES, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be99bbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train.pop('Species')\n",
    "test_y = test.pop('Species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a933012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, labels, training=True, batch_size=256):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features),labels))\n",
    "    \n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffe8f23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n",
      "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n",
      "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n",
      "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "my_feature_columns = []\n",
    "for key in train.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "    print(my_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e2fd5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\btany\\AppData\\Local\\Temp\\tmp90g6csa6\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\btany\\\\AppData\\\\Local\\\\Temp\\\\tmp90g6csa6', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.estimator.DNNClassifier(feature_columns = my_feature_columns, hidden_units = [30,10], n_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e36a034c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\btany\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\training_util.py:396: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From C:\\Users\\btany\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adagrad.py:93: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\btany\\AppData\\Local\\Temp\\tmp90g6csa6\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 1.2457014, step = 0\n",
      "INFO:tensorflow:global_step/sec: 372.414\n",
      "INFO:tensorflow:loss = 0.98833317, step = 100 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 531.821\n",
      "INFO:tensorflow:loss = 0.94550717, step = 200 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 663.574\n",
      "INFO:tensorflow:loss = 0.9008, step = 300 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 710.88\n",
      "INFO:tensorflow:loss = 0.8677059, step = 400 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 730.725\n",
      "INFO:tensorflow:loss = 0.8381146, step = 500 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 758.279\n",
      "INFO:tensorflow:loss = 0.8034071, step = 600 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 758.483\n",
      "INFO:tensorflow:loss = 0.77714276, step = 700 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 758.794\n",
      "INFO:tensorflow:loss = 0.75257564, step = 800 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 719.519\n",
      "INFO:tensorflow:loss = 0.72765064, step = 900 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 719.348\n",
      "INFO:tensorflow:loss = 0.7074616, step = 1000 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 723.736\n",
      "INFO:tensorflow:loss = 0.6849719, step = 1100 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 735.391\n",
      "INFO:tensorflow:loss = 0.6749171, step = 1200 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 603.417\n",
      "INFO:tensorflow:loss = 0.65499514, step = 1300 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 607.583\n",
      "INFO:tensorflow:loss = 0.644285, step = 1400 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 533.74\n",
      "INFO:tensorflow:loss = 0.62648314, step = 1500 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 609.369\n",
      "INFO:tensorflow:loss = 0.6083256, step = 1600 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 792.238\n",
      "INFO:tensorflow:loss = 0.59551, step = 1700 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.167\n",
      "INFO:tensorflow:loss = 0.5862482, step = 1800 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 634.202\n",
      "INFO:tensorflow:loss = 0.5729334, step = 1900 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 577.49\n",
      "INFO:tensorflow:loss = 0.5574126, step = 2000 (0.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.872\n",
      "INFO:tensorflow:loss = 0.55196047, step = 2100 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 785.385\n",
      "INFO:tensorflow:loss = 0.53188765, step = 2200 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 720.623\n",
      "INFO:tensorflow:loss = 0.5275471, step = 2300 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 757.512\n",
      "INFO:tensorflow:loss = 0.5222688, step = 2400 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 759.459\n",
      "INFO:tensorflow:loss = 0.50448287, step = 2500 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 710.2\n",
      "INFO:tensorflow:loss = 0.50479645, step = 2600 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 580.782\n",
      "INFO:tensorflow:loss = 0.49707633, step = 2700 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 573.383\n",
      "INFO:tensorflow:loss = 0.48961693, step = 2800 (0.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 632.446\n",
      "INFO:tensorflow:loss = 0.47546503, step = 2900 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 720.348\n",
      "INFO:tensorflow:loss = 0.4714911, step = 3000 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 759.063\n",
      "INFO:tensorflow:loss = 0.44894308, step = 3100 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 686.404\n",
      "INFO:tensorflow:loss = 0.44527227, step = 3200 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 758.215\n",
      "INFO:tensorflow:loss = 0.44938618, step = 3300 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 720.25\n",
      "INFO:tensorflow:loss = 0.43443853, step = 3400 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 712.35\n",
      "INFO:tensorflow:loss = 0.42506212, step = 3500 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 729.524\n",
      "INFO:tensorflow:loss = 0.43193382, step = 3600 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 758.423\n",
      "INFO:tensorflow:loss = 0.4167227, step = 3700 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 758.318\n",
      "INFO:tensorflow:loss = 0.4185471, step = 3800 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 719.726\n",
      "INFO:tensorflow:loss = 0.41420567, step = 3900 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 720.066\n",
      "INFO:tensorflow:loss = 0.39888513, step = 4000 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 721.698\n",
      "INFO:tensorflow:loss = 0.4149146, step = 4100 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 757.921\n",
      "INFO:tensorflow:loss = 0.39689994, step = 4200 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 619.32\n",
      "INFO:tensorflow:loss = 0.39291072, step = 4300 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 557.396\n",
      "INFO:tensorflow:loss = 0.3786237, step = 4400 (0.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 579.651\n",
      "INFO:tensorflow:loss = 0.38009048, step = 4500 (0.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 626.248\n",
      "INFO:tensorflow:loss = 0.3891731, step = 4600 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 758.56\n",
      "INFO:tensorflow:loss = 0.3739854, step = 4700 (0.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 720.826\n",
      "INFO:tensorflow:loss = 0.37365142, step = 4800 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 739.045\n",
      "INFO:tensorflow:loss = 0.3619045, step = 4900 (0.140 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into C:\\Users\\btany\\AppData\\Local\\Temp\\tmp90g6csa6\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:Loss for final step: 0.37310958.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x1b6f1a4ba60>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.train(input_fn=lambda: input_fn(train,train_y, training=True), steps=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f999818a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-04-16T03:59:34\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\btany\\AppData\\Local\\Temp\\tmp90g6csa6\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.27149s\n",
      "INFO:tensorflow:Finished evaluation at 2023-04-16-03:59:34\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.96666664, average_loss = 0.42273393, global_step = 5000, loss = 0.42273393\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: C:\\Users\\btany\\AppData\\Local\\Temp\\tmp90g6csa6\\model.ckpt-5000\n",
      "Test set accuracy: 0.967\n"
     ]
    }
   ],
   "source": [
    "eval_result = classifier.evaluate(input_fn=lambda: input_fn(test, test_y, training=False))\n",
    "print('Test set accuracy: {accuracy:0.3f}'.format(**eval_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63f4b296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type numeric values as prompted\n",
      "SepalLength:0.2\n",
      "SepalWidth:0.2\n",
      "PetalLength:0.2\n",
      "PetalWidth:0.2\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\btany\\AppData\\Local\\Temp\\tmp90g6csa6\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prediction is \"Versicolor\" (38.8%)\n"
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "def input_fn(features, labels = 256):\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
    "\n",
    "features = ['SepalLength', 'SepalWidth','PetalLength', 'PetalWidth']\n",
    "predict = {}\n",
    "\n",
    "print('Please type numeric values as prompted')\n",
    "\n",
    "for feature in features:\n",
    "    valid = True\n",
    "    while valid:\n",
    "        val = input(feature + ':')\n",
    "        if not val.isdigit(): valid=False\n",
    "    predict[feature] = [float(val)]\n",
    "\n",
    "predictions = classifier.predict(input_fn = lambda: input_fn(predict))\n",
    "for pred_dict in predictions:\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "    \n",
    "    print('Prediction is \"{}\" ({:.1f}%)'.format(SPECIES[class_id], 100*probability))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
